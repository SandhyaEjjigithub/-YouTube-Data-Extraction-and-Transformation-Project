import json
from googleapiclient.discovery import build
import os
import boto3
from datetime import datetime
from googleapiclient.errors import HttpError

# Function to fetch raw statistics data for a given YouTube channel ID
def get_channel_stats_raw(youtube, channel_id):
    try:
        request = youtube.channels().list(
            part='snippet,contentDetails,statistics',
            id=channel_id)
        response = request.execute()
        return response
    except HttpError as e:
        print(f"HttpError: {e}")
        if e.resp.status in [403]:
            print("Quota exceeded or access forbidden.")
        raise e

# Function to retrieve video IDs from a given playlist ID
def get_video_ids(youtube, playlist_id):
    try:
        request = youtube.playlistItems().list(
            part='contentDetails',
            playlistId=playlist_id,
            maxResults=5)  # Further lowered to 5 results
        response = request.execute()

        video_ids = [item['contentDetails']['videoId'] for item in response['items']]

        next_page_token = response.get('nextPageToken')

        while next_page_token:
            request = youtube.playlistItems().list(
                part='contentDetails',
                playlistId=playlist_id,
                maxResults=5,
                pageToken=next_page_token)
            response = request.execute()

            video_ids.extend(item['contentDetails']['videoId'] for item in response['items'])
            next_page_token = response.get('nextPageToken')

        return video_ids
    except HttpError as e:
        print(f"HttpError: {e}")
        raise e

# Function to retrieve details of videos using their IDs
def get_video_details(youtube, video_ids):
    all_data = []
    try:
        for i in range(0, len(video_ids), 5):  # Further lowered to chunks of 5
            request = youtube.videos().list(
                part='snippet,statistics',
                id=','.join(video_ids[i:i+5]))
            response = request.execute()
            all_data.append(response)
        return all_data
    except HttpError as e:
        print(f"HttpError: {e}")
        raise e

# Function to retrieve comments data for given video IDs
def get_comments_data(youtube, video_ids):
    all_comments = []
    try:
        for video_id in video_ids:
            try:
                request = youtube.commentThreads().list(
                    part="snippet",
                    videoId=video_id,
                    textFormat="plainText",
                    maxResults=10)  # Further lowered to 10 results
                response = request.execute()
                all_comments.append(response)

                while "nextPageToken" in response:
                    request = youtube.commentThreads().list(
                        part="snippet",
                        videoId=video_id,
                        textFormat="plainText",
                        maxResults=10,
                        pageToken=response["nextPageToken"])
                    response = request.execute()
                    all_comments.append(response)
            except HttpError as e:
                if e.resp.status == 403:
                    print(f"Comments are disabled for video with ID: {video_id}. Skipping comments retrieval.")
                    continue
                else:
                    raise e
        return all_comments
    except HttpError as e:
        print(f"HttpError: {e}")
        raise e

# Lambda handler function
def lambda_handler(event, context):
    results = []
    client_id = os.environ.get('client_id')
    channel_ids = ['UCChmJrVa8kDg05JfCmxpLRw','UCnnQ3ybuyFdzvgv2Ky5jnAA']  # Process only one channel to reduce calls
    youtube = build('youtube', 'v3', developerKey=client_id)
    client = boto3.client('s3')

    for channel_id in channel_ids:
        try:
            channel_raw_data = get_channel_stats_raw(youtube, channel_id)
            filename_channel = "channel_raw_data_" + str(datetime.now()) + ".json"
            client.put_object(
                Bucket="youtubebucket-forextracting",
                Key="raw_data/to_processed/channel_data/" + filename_channel,
                Body=json.dumps(channel_raw_data)
            )
            results.append({"channel_id": channel_id, "status": "channel data stored"})

            playlist_id = channel_raw_data['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            video_ids_duplicate = get_video_ids(youtube, playlist_id)
            video_ids = list(set(video_ids_duplicate))

            all_videos_raw_data = get_video_details(youtube, video_ids)
            filename_video = "video_raw_data_" + str(datetime.now()) + ".json"
            client.put_object(
                Bucket="youtubebucket-forextracting",
                Key="raw_data/to_processed/video_data/" + filename_video,
                Body=json.dumps(all_videos_raw_data)
            )
            results.append({"channel_id": channel_id, "status": "video data stored"})

            comments_raw_data = get_comments_data(youtube, video_ids)
            filename_comments = "comments_raw_data_" + str(datetime.now()) + ".json"
            client.put_object(
                Bucket="youtubebucket-forextracting",
                Key="raw_data/to_processed/comments_data/" + filename_comments,
                Body=json.dumps(comments_raw_data)
            )
            results.append({"channel_id": channel_id, "status": "comments data stored"})
        except HttpError as e:
            results.append({"channel_id": channel_id, "status": f"failed: {e}"})

    # Start AWS Glue job run
    glue = boto3.client("glue")
    gluejobname = "YouTubeDataProcessingJob"
    try:
        runId = glue.start_job_run(JobName=gluejobname)
        status = glue.get_job_run(JobName=gluejobname, RunId=runId['JobRunId'])
        glue_status = status['JobRun']['JobRunState']
    except Exception as e:
        glue_status = str(e)

    return {
        "statusCode": 200,
        "body": json.dumps({
            "message": "Processing completed successfully.",
            "results": results,
            "glue_job_status": glue_status
        })
    }
